{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from os.path import join\n",
    "import multiprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_HOME = '../CASIA-WebFace-Cropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('webface.train.csv', nrows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataset['person'])\n",
    "dataset['person_id'] = encoder.transform(dataset['person'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>count</th>\n",
       "      <th>path</th>\n",
       "      <th>person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3331486</td>\n",
       "      <td>13</td>\n",
       "      <td>3331486/012.jpg</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3331486</td>\n",
       "      <td>13</td>\n",
       "      <td>3331486/010.jpg</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3331486</td>\n",
       "      <td>13</td>\n",
       "      <td>3331486/006.jpg</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3331486</td>\n",
       "      <td>13</td>\n",
       "      <td>3331486/008.jpg</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3331486</td>\n",
       "      <td>13</td>\n",
       "      <td>3331486/001.jpg</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    person  count             path  person_id\n",
       "0  3331486     13  3331486/012.jpg       1107\n",
       "1  3331486     13  3331486/010.jpg       1107\n",
       "2  3331486     13  3331486/006.jpg       1107\n",
       "3  3331486     13  3331486/008.jpg       1107\n",
       "4  3331486     13  3331486/001.jpg       1107"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = dataset['person_id'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65707\n"
     ]
    }
   ],
   "source": [
    "img_paths = [r.path for r in dataset.itertuples()]\n",
    "print(len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def path2ImgVec(path):\n",
    "    x = img_to_array(load_img(join(DATA_HOME, path)))\n",
    "    return x.reshape((1,) + x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(8)\n",
    "results = pool.map(path2ImgVec, img_paths)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.vstack(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65707, 55, 47, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_class 2027\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import LSTM\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import metrics\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.engine import Model\n",
    "from keras import optimizers\n",
    "\n",
    "nb_class = len(np.unique(y))\n",
    "print('nb_class', nb_class)\n",
    "hidden_dim = 160\n",
    "best_weights_filepath = '../models/best_weights.hdf5'\n",
    "\n",
    "def build_model():\n",
    "    image_input = Input(shape=X.shape[1:])\n",
    "    \n",
    "    conv1 = Conv2D(20, (4, 4), name='conv1')(image_input)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), name='pool1')(conv1)\n",
    "#     pool1 = Dropout(rate=0.2)(pool1)\n",
    "    \n",
    "    conv2 = Conv2D(40, (3, 3), name='conv2')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), name='pool2')(conv2)\n",
    "#     pool2 = Dropout(rate=0.2)(pool2)\n",
    "\n",
    "    conv3 = Conv2D(60, (3, 3), name='conv3')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), name='pool3')(conv3)\n",
    "\n",
    "    flat1 = Flatten(name='flat1')(pool3)\n",
    "    \n",
    "    conv4 = Conv2D(80, (2, 2), name='conv4')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    flat2 = Flatten(name='flat2')(conv4)\n",
    "    \n",
    "    merged = concatenate([flat1, flat2])\n",
    "    \n",
    "    out = Dense(hidden_dim, name='hidden1')(merged)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dense(nb_class, activation='softmax', name='softmax_class')(out)\n",
    "    \n",
    "    model = Model(inputs=image_input, outputs=out)\n",
    "\n",
    "    optimizer = optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=10*(1e-5))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer, #rmsprop\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_31 (InputLayer)            (None, 55, 47, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 52, 44, 20)    980                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, 52, 44, 20)    80                                           \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, 52, 44, 20)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)             (None, 26, 22, 20)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                   (None, 24, 20, 40)    7240                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, 24, 20, 40)    160                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, 24, 20, 40)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)             (None, 12, 10, 40)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                   (None, 10, 8, 60)     21660                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, 10, 8, 60)     240                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, 10, 8, 60)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)             (None, 5, 4, 60)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                   (None, 4, 3, 80)      19280                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNor (None, 4, 3, 80)      320                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_103 (Activation)      (None, 4, 3, 80)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flat1 (Flatten)                  (None, 1200)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flat2 (Flatten)                  (None, 960)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)     (None, 2160)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "hidden1 (Dense)                  (None, 160)           345760                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNor (None, 160)           640                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_104 (Activation)      (None, 160)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "softmax_class (Dense)            (None, 2027)          326347                                       \n",
      "====================================================================================================\n",
      "Total params: 722,707.0\n",
      "Trainable params: 721,987.0\n",
      "Non-trainable params: 720.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53222 samples, validate on 5914 samples\n",
      "Epoch 1/15\n",
      "10s - loss: 7.1765 - acc: 0.0205 - val_loss: 7.1463 - val_acc: 0.0287\n",
      "Epoch 2/15\n",
      "6s - loss: 6.2491 - acc: 0.0668 - val_loss: 6.3172 - val_acc: 0.0769\n",
      "Epoch 3/15\n",
      "6s - loss: 5.3891 - acc: 0.1355 - val_loss: 5.5329 - val_acc: 0.1302\n",
      "Epoch 4/15\n",
      "6s - loss: 4.5921 - acc: 0.2254 - val_loss: 5.0318 - val_acc: 0.1848\n",
      "Epoch 5/15\n",
      "6s - loss: 3.8624 - acc: 0.3325 - val_loss: 4.6510 - val_acc: 0.2249\n",
      "Epoch 6/15\n",
      "6s - loss: 3.2332 - acc: 0.4331 - val_loss: 4.4358 - val_acc: 0.2621\n",
      "Epoch 7/15\n",
      "6s - loss: 2.6922 - acc: 0.5253 - val_loss: 4.2339 - val_acc: 0.2902\n",
      "Epoch 8/15\n",
      "6s - loss: 2.2385 - acc: 0.6026 - val_loss: 4.1363 - val_acc: 0.3118\n",
      "Epoch 9/15\n",
      "6s - loss: 1.8555 - acc: 0.6740 - val_loss: 4.0717 - val_acc: 0.3236\n",
      "Epoch 10/15\n",
      "6s - loss: 1.5245 - acc: 0.7358 - val_loss: 4.1222 - val_acc: 0.3250\n",
      "Epoch 11/15\n",
      "6s - loss: 1.2460 - acc: 0.7892 - val_loss: 4.1514 - val_acc: 0.3312\n",
      "Epoch 12/15\n",
      "6s - loss: 1.0061 - acc: 0.8367 - val_loss: 4.1275 - val_acc: 0.3358\n",
      "Epoch 13/15\n",
      "6s - loss: 0.8004 - acc: 0.8795 - val_loss: 4.2960 - val_acc: 0.3262\n",
      "Epoch 14/15\n",
      "6s - loss: 0.6312 - acc: 0.9136 - val_loss: 4.3682 - val_acc: 0.3218\n",
      "Epoch 15/15\n",
      "6s - loss: 0.4875 - acc: 0.9426 - val_loss: 4.4580 - val_acc: 0.3167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2525283da0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saveBestModel = keras.callbacks.ModelCheckpoint(\n",
    "    best_weights_filepath, \n",
    "    monitor='val_acc', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    mode='auto'\n",
    ")\n",
    "earlyStopping=keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    verbose=1, \n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size=512, \n",
    "    epochs=15,\n",
    "    verbose=2, \n",
    "    validation_split=0.1, \n",
    "    shuffle=True,\n",
    "    callbacks=[saveBestModel, earlyStopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(best_weights_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('../models/webface-simple-cnn.3348.model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.1487823227844798, 0.33039111330291121]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=256, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
